import streamlit as st
import pandas as pd
import base64
import openpyxl
import io

@st.cache_resource
def process(df):
    needval_condition = df.duplicated(subset=['Udise', 'Action Item'], keep=False) & (
      df.groupby(['Udise', 'Action Item'])['quantity'].transform('nunique') > 1
    )
    dupli_condition = df.duplicated(subset=['Udise', 'Action Item'], keep=False) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: (x == 0)  | (x > 30))) | (df.duplicated(subset=['Udise', 'Action Item', 'quantity'], keep='first')
    )
    dup_zero = df.duplicated(subset=['Udise', 'Action Item']) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: all((x == 0)  | (x > 30))))
  
    df['verified'] = [False]*len(df)
    df['need validation'] = [False]*len(df)
    df['isduplicate'] = [False]*len(df)
    df.loc[dupli_condition, 'isduplicate'] = True
    df.loc[dup_zero, 'isduplicate'] = False
  
  
    need_val = []
    for i in df['quantity']:
        if i > 30 or i == 0 :
            need_val.append(True)
        else:
            need_val.append(False)
  
    df['need validation'] = need_val
    df.loc[needval_condition, 'need validation'] = True
    df['verified'] = ''
    df.loc[df['isduplicate'] == False , 'verified'] = True
    df.loc[df['need validation'] == False , 'verified'] = True
    df['System_Status'] = ''
    df.loc[df['verified'] == True , 'System_Status'] = 'Verified'
    df.loc[df['need validation'] == True , 'System_Status'] = 'Need_validation'
    df.loc[df['isduplicate'] == True , 'System_Status'] = 'Duplicate'

    columns_to_drop = ['isduplicate', 'need validation', 'verified']
    new_df = df.drop(columns=columns_to_drop)
    return new_df

@st.cache_resource
def enhanced_process(df):
    action_items_list =  [
    'à®šà¯à®µà®°à®¿à®²à¯ à®¨à¯€à®°à¯ à®’à®´à¯à®•à¯à®¤à®²à¯ à®ªà®´à¯à®¤à¯à®ªà¯à®ªà®¾à®°à¯à®¤à¯à®¤à®²à¯',
    'à®šà¯à®±à¯à®±à¯à®šà¯à®šà¯à®µà®°à¯ à®ªà®´à¯à®¤à¯à®ªà¯à®ªà®¾à®°à¯à®¤à¯à®¤à®²à¯',
    'à®¤à®°à¯ˆ à®šà¯€à®°à®®à¯ˆà®ªà¯à®ªà¯ à®šà¯†à®¯à¯à®¤à®²à¯',
    'à®¤à®°à¯ˆà®¤à¯ à®¤à®³ à®“à®Ÿà¯ à®ªà®¤à®¿à®¤à¯à®¤à®²à¯',
    'à®ªà®Ÿà¯à®Ÿà®¿ à®ªà®¾à®°à¯à®¤à¯à®¤à®²à¯',
    'à®ªà®´à¯à®¤à®Ÿà¯ˆà®¨à¯à®¤ à®šà¯à®±à¯à®±à¯à®šà¯à®šà¯à®µà®°à¯ˆ à®…à®•à®±à¯à®±à¯à®¤à®²à¯',
    'à®ªà®´à¯à®¤à¯à®ªà¯à®ªà®¾à®°à¯à®¤à¯à®¤à®²à¯',
    'à®ªà¯à®¤à®¿à®¯ à®‡à®¯à®±à¯à®ªà®¿à®¯à®²à¯ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®‰à®Ÿà®±à¯à®•à®²à¯à®µà®¿ à®†à®šà®¿à®°à®¿à®¯à®°à¯à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®‰à®¯à®°à¯-à®¤à¯Šà®´à®¿à®¨à¯à®Ÿà¯à®ª à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®‰à®¯à®¿à®°à®¿à®¯à®²à¯ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®’à®°à¯à®™à¯à®•à®¿à®£à¯ˆà®¨à¯à®¤ à®…à®±à®¿à®µà®¿à®¯à®²à¯ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®•à®£à®¿à®¤ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®•à®£à®¿à®©à®¿ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®•à®²à¯ˆ à®†à®¯à¯à®µà®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®•à®²à¯ˆà®¯à®°à®™à¯à®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®•à®´à®¿à®µà¯à®¨à¯€à®°à¯à®¤à¯ à®¤à¯‡à®•à¯à®•à®¤à¯ à®¤à¯Šà®Ÿà¯à®Ÿà®¿',
    'à®ªà¯à®¤à®¿à®¯ à®šà®®à¯ˆà®¯à®²à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®šà®®à¯ˆà®¯à®²à¯ à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®šà¯à®±à¯à®±à¯à®šà¯ à®šà¯à®µà®°à¯',
    'à®ªà¯à®¤à®¿à®¯ à®šà¯‡à®®à®¿à®ªà¯à®ªà¯ à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®šà¯‡à®²à®ªà®¾à®Ÿà¯à®Ÿà¯ à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®¨à®¿à®°à¯à®µà®¾à®• à®…à®²à¯à®µà®²à®• à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®¨à®¿à®²à®¤à¯à®¤à®Ÿà®¿à®¤à¯ à®¤à¯Šà®Ÿà¯à®Ÿà®¿',
    'à®ªà¯à®¤à®¿à®¯ à®¨à¯‚à®²à®•à®®à¯',
    'à®ªà¯à®¤à®¿à®¯ à®ªà®¤à®¿à®µà®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®ªà®®à¯à®ªà¯ à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®ªà®¾à®¤à¯à®•à®¾à®ªà¯à®ªà®¾à®³à®°à¯ à®…à®±à¯ˆ',
    'à®ªà¯à®¤à®¿à®¯ à®µà¯‡à®¤à®¿à®¯à®¿à®¯à®²à¯ à®†à®¯à¯à®µà®•à®®à¯',
    'à®®à¯‡à®±à¯à®•à¯‚à®°à¯ˆ à®ªà¯‚à®šà¯à®¤à®²à¯',
    'à®®à¯‡à®±à¯à®ªà¯‚à®šà®šà¯ à®ªà¯‚à®šà¯à®¤à®²à¯'
    ]

    needval_condition = df.duplicated(subset=['Udise', 'Action Item'], keep=False) & (
    df.groupby(['Udise', 'Action Item'])['quantity'].transform('nunique') > 1
    )
    dupli_condition = df.duplicated(subset=['Udise', 'Action Item'], keep=False) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: (x == 0)  | (x > 30))) | (df.duplicated(subset=['Udise', 'Action Item', 'quantity'], keep='first')
    )
    dup_zero = df.duplicated(subset=['Udise', 'Action Item']) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: all((x == 0)  | (x > 30))))
    
    veri_one = df.duplicated(subset=['Udise', 'Action Item']) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: (x == 1))) & (
        df.groupby(['Udise', 'Action Item'])['Action Item'].transform(lambda x: x.isin(action_items_list)))
    
    veri_many = df.duplicated(subset=['Udise', 'Action Item']) & (
        df.groupby(['Udise', 'Action Item'])['quantity'].transform(lambda x: (x > 1))) & (
        df.groupby(['Udise', 'Action Item'])['Action Item'].transform(lambda x: x.isin(action_items_list)))
    
    df['verified'] = [False]*len(df)
    df['need validation'] = [False]*len(df)
    df['isduplicate'] = [False]*len(df)
    df.loc[dupli_condition, 'isduplicate'] = True
    df.loc[dup_zero, 'isduplicate'] = False
    
    need_val = []
    for i in df['quantity']:
      if i > 30 or i == 0 :
        need_val.append(True)
      else:
        need_val.append(False)
    
    df['need validation'] = need_val
    df.loc[needval_condition, 'need validation'] = True
    
    df['verified'] = ''
    df.loc[df['isduplicate'] == False , 'verified'] = True
    df.loc[df['need validation'] == False , 'verified'] = True
    
    df.loc[veri_one, 'verified'] = True
    df.loc[veri_one, 'need validation'] = False
    
    df.loc[veri_many, 'verified'] = False
    df.loc[veri_many, 'need validation'] = True
    
    df['System_Status'] = ''
    df.loc[df['verified'] == True , 'System_Status'] = 'Verified'
    df.loc[df['need validation'] == True , 'System_Status'] = 'Need_validation'
    df.loc[df['isduplicate'] == True , 'System_Status'] = 'Duplicate'

    def create_duplicates(df, action_item, index):
        return (
            df.duplicated(subset=['Udise', 'Action Item']) & (
                df.groupby(['Udise', 'Action Item', 'quantity'])['quantity'].transform(lambda x: (x != 0) & (x > 1)) & (
                    df.groupby(['Udise'])['Action Item'].transform(lambda x: x == action_item)
                )
            )
        )
    
    df = df.sort_values(by = 'quantity')
    for i, action_item in enumerate(action_items_list, start=1):
        dup_var = f"dup_{i}"
        dup_condition = create_duplicates(df, action_item, i)
        df.loc[dup_condition, 'System_Status'] = 'Duplicate'

    def update_status(df, action_item):
        mixed_groups = df.groupby(['Udise', 'Action Item'])

        for name, group in mixed_groups:
            if name[1] == action_item:
                zero_exists = (group['quantity'] == 0).any()
                ten_exists = (group['quantity'] > 1).any()
    
                if zero_exists and ten_exists:
                    zero_idx = group[group['quantity'] == 0].index
                    df.loc[zero_idx, 'System_Status'] = 'Need_validation'

    for action_item in action_items_list:
        update_status(df, action_item)

    # Find single entries for each Udise-Action Item combination
    single_entries = df.groupby(['Udise', 'Action Item']).filter(lambda x: len(x) == 1)
    
    # Locate the index of those single entries with 'Verified' status and quantity greater than 1
    single_entries_index = single_entries[
        (single_entries['System_Status'] == 'Verified') &
        (single_entries['quantity'] > 1) & (single_entries['quantity'] != 0)
    ].index
    
    # Update the 'System_Status' for those single entries to 'Need_validation'
    df.loc[single_entries_index, 'System_Status'] = 'Need_validation'

    columns_to_drop = ['isduplicate', 'need validation', 'verified']
    new_df = df.drop(columns=columns_to_drop)
    return new_df

st.set_page_config(page_title="Excel Data Processing App", page_icon="ðŸ“Š")

st.title("Excel Data Processing App ðŸ“Š")
uploaded_file = st.file_uploader("Upload an Excel file", type=["xlsx", "xls"])

page = st.sidebar.radio("**Select a Page**",["Algorithm without Enhancement", "Algorithm with Enhancement based on Action Item"])

if page == "Algorithm without Enhancement":

    st.header("Algorithm without Enhancement")

    if uploaded_file is not None:
        try:
            # Read the Excel file
            data = pd.read_excel(uploaded_file)
    
            required_columns = ['Udise', 'Action Item', 'quantity']
            if not all(column in data.columns for column in required_columns):
                st.error(f"The uploaded dataset must contain the following columns: {', '.join(required_columns)}")
    
            else:
                st.subheader("View Original Data") 
                st.write(data)
                
                df_processed = process(data)
        
                st.subheader("View Processed Data")
                st.write(df_processed)
                
                st.subheader("Download Processed Data")
                excel_buffer = io.BytesIO()
                df_processed.to_excel(excel_buffer, index=False, header=True)
                excel_buffer.seek(0)
                b64 = base64.b64encode(excel_buffer.read()).decode()
                href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="processed_data_without_enhancement.xlsx">Click here to download Processed Data</a>'
                st.markdown(href, unsafe_allow_html=True)
            
        except pd.errors.ParserError:
            st.error("The uploaded dataset is not in a valid format.")
            data = none

elif page == "Algorithm with Enhancement based on Action Item":

    st.header("Algorithm with Enhancement based on Action Item")

    if uploaded_file is not None:
        try:
            # Read the Excel file
            data = pd.read_excel(uploaded_file)
    
            required_columns = ['Udise', 'Action Item', 'quantity']
            if not all(column in data.columns for column in required_columns):
                st.error(f"The uploaded dataset must contain the following columns: {', '.join(required_columns)}")
    
            else:
                st.subheader("View Original Data") 
                st.write(data)
                
                df_processed = enhanced_process(data)
        
                st.subheader("View Processed Data")
                st.write(df_processed)
                
                st.subheader("Download Processed Data")
                excel_buffer = io.BytesIO()
                df_processed.to_excel(excel_buffer, index=False, header=True)
                excel_buffer.seek(0)
                b64 = base64.b64encode(excel_buffer.read()).decode()
                href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="processed_data_with_enhancement.xlsx">Click here to download Processed Data</a>'
                st.markdown(href, unsafe_allow_html=True)
            
        except pd.errors.ParserError:
            st.error("The uploaded dataset is not in a valid format.")
            data = none
